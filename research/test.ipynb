{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb06a790",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, List, Literal\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class RAG(BaseModel) : \n",
    "\n",
    "    answer :str = Field(description=\"The answer to the question\")\n",
    "    source_documents : List[str] = Field(description=\"The source documents used to generate the answer\")\n",
    "\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    \"\"\"\n",
    "    Represents the state of our graph.\n",
    "\n",
    "    Attributes:\n",
    "        question: question\n",
    "        generation: LLM generation\n",
    "        documents: list of documents\n",
    "    \"\"\"\n",
    "\n",
    "    question: str\n",
    "    generation: str\n",
    "    number_of_document_tries: int\n",
    "    documents: List[str]\n",
    "    upload_status: str\n",
    "    source_type: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d97660ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mahdi/projects/Aegis/.venv/lib/python3.12/site-packages/torch/cuda/__init__.py:182: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11060). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at /pytorch/c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "\n",
    "embedding=HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a71566a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_astradb import AstraDBVectorStore\n",
    "import os\n",
    "\n",
    "vectorstore = AstraDBVectorStore(\n",
    "                embedding=embedding,\n",
    "                api_endpoint=os.getenv('ASTRA_DB_API_ENDPOINT'),\n",
    "                token=os.getenv('ASTRA_DB_APPLICATION_TOKEN'),\n",
    "                namespace= None,\n",
    "                collection_name=\"astra_vector_langchain\", \n",
    "            )\n",
    "\n",
    "retriever=vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d2c991b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_groq import ChatGroq \n",
    "llm = ChatGroq(model=\"moonshotai/kimi-k2-instruct-0905\")\n",
    "system = \"\"\"You are a grader assessing whether an LLM generation answers a user question.\n",
    "\n",
    "            You must respond with ONLY a JSON object in this exact format:\n",
    "            {{\"binary_score\": \"yes\"}} or {{\"binary_score\": \"no\"}}\n",
    "\n",
    "            Rules:\n",
    "            - \"yes\" means the answer addresses and answers the user's question\n",
    "            - \"no\" means the answer does not address the user's question\n",
    "            - Respond with ONLY the JSON object, nothing else\"\"\"\n",
    "            \n",
    "answer_prompt = ChatPromptTemplate.from_messages([\n",
    "                (\"system\", system),\n",
    "                (\"human\", \"User question: \\n\\n {question} \\n\\n LLM generation: {generation}\\n\\nResponse (JSON only):\"),\n",
    "            ])\n",
    "\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "json_parser = JsonOutputParser()\n",
    "            \n",
    "answer_grader = answer_prompt |llm | json_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc360bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "system = \"\"\"You are a grader assessing whether an LLM generation is grounded in / supported by a set of retrieved facts.\n",
    "\n",
    "            You must respond with ONLY a JSON object in this exact format:\n",
    "            {{\"binary_score\": \"yes\"}} or {{\"binary_score\": \"no\"}}\n",
    "\n",
    "            Rules:\n",
    "            - \"yes\" means the answer is grounded in and supported by the provided facts\n",
    "            - \"no\" means the answer contains information not supported by the facts\n",
    "            - Respond with ONLY the JSON object, nothing else\"\"\"\n",
    "            \n",
    "hallucination_prompt = ChatPromptTemplate.from_messages([\n",
    "                (\"system\", system),\n",
    "                (\"human\", \"Set of facts: \\n\\n {documents} \\n\\n LLM generation: {generation}\\n\\nResponse (JSON only):\"),\n",
    "            ])\n",
    "\n",
    "            # Use JSON mode instead of structured output for better reliability\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "json_parser = JsonOutputParser()\n",
    "\n",
    "hallucination_grader = hallucination_prompt | llm | json_parser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8905be05",
   "metadata": {},
   "outputs": [],
   "source": [
    "system = \"\"\"You a question re-writer that converts an input question to a better version that is optimized \\n \n",
    "            for vectorstore retrieval. Look at the input and try to reason about the underlying semantic intent / meaning.\"\"\"\n",
    "re_write_prompt = ChatPromptTemplate.from_messages(\n",
    "                [\n",
    "                    (\"system\", system),\n",
    "                    (\n",
    "                        \"human\",\n",
    "                        \"Here is the initial question: \\n\\n {question} \\n Formulate an improved question.\",\n",
    "                    ),\n",
    "                ]\n",
    "            )\n",
    "\n",
    "question_rewriter = re_write_prompt | llm | StrOutputParser()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "baa0197e",
   "metadata": {},
   "outputs": [],
   "source": [
    "system = \"\"\"You are an expert at routing user questions to either a vectorstore or web search.\n",
    "\n",
    "            You must respond with ONLY a JSON object in this exact format:\n",
    "            {{\"datasource\": \"vectorstore\"}} or {{\"datasource\": \"web_search\"}}\n",
    "\n",
    "            The vectorstore contains documents about: AI agents, prompt engineering, and adversarial attacks.\n",
    "            \n",
    "            Rules:\n",
    "            - Use \"vectorstore\" for questions about: AI agents, prompt engineering, adversarial attacks, LLMs, machine learning concepts\n",
    "            - Use \"vectorstore\" for simple greetings, casual conversations, or non-specific questions (like \"hi\", \"hello\", \"how are you\")\n",
    "            - Use \"web_search\" ONLY for questions requiring current/recent information, news, weather, or specific factual queries not covered by the vectorstore\n",
    "            \n",
    "            Default to \"vectorstore\" unless you're certain the question needs current web information.\n",
    "            Respond with ONLY the JSON object, nothing else.\"\"\"\n",
    "            \n",
    "route_prompt = ChatPromptTemplate.from_messages([\n",
    "                (\"system\", system),\n",
    "                (\"human\", \"{question}\\n\\nResponse (JSON only):\"),\n",
    "            ])\n",
    "\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "json_parser = JsonOutputParser()\n",
    "\n",
    "question_router = route_prompt | llm | json_parser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06933f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "prompt = hub.pull(\"rlm/rag-prompt\") \n",
    "\n",
    "                # Fallback to custom prompt\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "                    (\"system\", \"\"\"You are a helpful AI assistant. Use the provided context to answer questions accurately.\n",
    "                    \n",
    "                    If the question is a simple greeting or casual conversation (like \"hi\", \"hello\", \"how are you\"), \n",
    "                    respond naturally and friendly without requiring specific context.\n",
    "                    \n",
    "                    For knowledge questions, use the provided context to give accurate, helpful answers.\n",
    "                    If you don't have enough context to answer a question, say so clearly.\n",
    "                    \n",
    "                    Context: {context}\"\"\"),\n",
    "                    (\"human\", \"{question}\")\n",
    "                ])\n",
    "            \n",
    "rag_chain = prompt | llm | StrOutputParser() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bf072aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "system = \"\"\"You are a grader assessing relevance of a retrieved document to a user question.\n",
    "\n",
    "            You must respond with ONLY a JSON object in this exact format:\n",
    "            {{\"binary_score\": \"yes\"}} or {{\"binary_score\": \"no\"}}\n",
    "\n",
    "            Rules:\n",
    "            - If the document contains keywords or semantic meaning related to the user question, grade it as \"yes\"\n",
    "            - It does not need to be a stringent test. The goal is to filter out completely irrelevant retrievals\n",
    "            - \"yes\" means the document is relevant to the question\n",
    "            - \"no\" means the document is not relevant to the question\n",
    "            - Respond with ONLY the JSON object, nothing else\"\"\"\n",
    "            \n",
    "grade_prompt = ChatPromptTemplate.from_messages([\n",
    "                (\"system\", system),\n",
    "                (\"human\", \"Retrieved document: \\n\\n {document} \\n\\n User question: {question}\\n\\nResponse (JSON only):\"),\n",
    "            ])\n",
    "            \n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "json_parser = JsonOutputParser()\n",
    "            \n",
    "retrieval_grader = grade_prompt | llm | json_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b2a50fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_165415/1277798333.py:3: LangChainDeprecationWarning: The class `TavilySearchResults` was deprecated in LangChain 0.3.25 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-tavily package and should be used instead. To use it run `pip install -U :class:`~langchain-tavily` and import as `from :class:`~langchain_tavily import TavilySearch``.\n",
      "  web_search_tool = TavilySearchResults(\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "web_search_tool = TavilySearchResults(\n",
    "    api_key=os.getenv(\"TAVILY_API_KEY\"),\n",
    "    k=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "70bd8610",
   "metadata": {},
   "outputs": [],
   "source": [
    "from db_test import test_astra_connection\n",
    "from langchain_astradb import AstraDBVectorStore\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.documents import Document\n",
    "load_dotenv()\n",
    "\n",
    "class upload_generated_answers:\n",
    "\n",
    "    def __init__ (self, documents, answer): \n",
    "        self.source_documents = documents\n",
    "        self.answer = answer\n",
    "        self.embedder = embedding  # Use the global embedding variable\n",
    "        self.vectorstore = None\n",
    "\n",
    "\n",
    "    def upload_answer(self):\n",
    "        try: \n",
    "            api_endpoint = os.getenv('ASTRA_DB_API_ENDPOINT')\n",
    "            token = os.getenv('ASTRA_DB_APPLICATION_TOKEN')\n",
    "\n",
    "            testing_db = test_astra_connection()\n",
    "            if testing_db == True : \n",
    "                print(\"Connected to Astra DB successfully!\")\n",
    "                self.vectorstore = AstraDBVectorStore(\n",
    "                embedding=self.embedder,\n",
    "                api_endpoint=api_endpoint,\n",
    "                token=token,\n",
    "                collection_name=\"astra_vector_langchain\",\n",
    "            )\n",
    "                # Extract text content from documents for metadata (JSON serializable)\n",
    "                if hasattr(self.source_documents, 'page_content'):\n",
    "                    # Single document\n",
    "                    source_text = [self.source_documents.page_content]\n",
    "                elif isinstance(self.source_documents, list):\n",
    "                    # List of documents\n",
    "                    source_text = [doc.page_content if hasattr(doc, 'page_content') else str(doc) for doc in self.source_documents]\n",
    "                else:\n",
    "                    # Fallback\n",
    "                    source_text = [str(self.source_documents)]\n",
    "                \n",
    "                Document_to_upload = Document(\n",
    "                    page_content=self.answer,\n",
    "                    metadata={\"source_documents\": source_text, \"producer\" : \"Generated_Web_Search_Answer\"}\n",
    "                )\n",
    "\n",
    "            print(\"Uploading answer and source documents to Astra DB...\")\n",
    "            self.vectorstore.add_documents([Document_to_upload])\n",
    "\n",
    "            return \"Upload successful\"\n",
    "        except Exception as e: \n",
    "            raise ValueError(f\"Error occurred with exception : {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e515cd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a8279b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(state: GraphState):\n",
    "        \"\"\"\n",
    "        Retrieve documents\n",
    "\n",
    "        Args:\n",
    "            state (dict): The current graph state\n",
    "\n",
    "        Returns:\n",
    "            state (dict): New key added to state, documents, that contains retrieved documents\n",
    "        \"\"\"\n",
    "        print(\"---RETRIEVE---\")\n",
    "        question = state[\"question\"]\n",
    "        attempts = state.get(\"number_of_document_tries\", 0)\n",
    "        upload_status = state.get(\"upload_status\", \"False\")\n",
    "        \n",
    "        # Retrieval\n",
    "        documents = retriever.invoke(question)\n",
    "        return {\n",
    "            \"documents\": documents, \n",
    "            \"question\": question, \n",
    "            \"number_of_document_tries\": attempts, \n",
    "            \"upload_status\": upload_status,\n",
    "            \"source_type\": \"vectorstore\"\n",
    "        }\n",
    "    \n",
    "\n",
    "def generate(state: GraphState): \n",
    "        \"\"\"\n",
    "        Generate answer\n",
    "\n",
    "        Args:\n",
    "            state (dict): The current graph state\n",
    "\n",
    "        Returns:\n",
    "            state (dict): New key added to state, generation, that contains LLM generation\n",
    "        \"\"\"\n",
    "        print(\"---GENERATE---\")\n",
    "        question = state[\"question\"]\n",
    "        documents = state[\"documents\"]\n",
    "        attempts = state.get(\"number_of_document_tries\", 0)\n",
    "        upload_status = state.get(\"upload_status\", \"False\")\n",
    "        source_type = state.get(\"source_type\", \"unknown\")\n",
    "\n",
    "        # RAG generation\n",
    "        generation = rag_chain.invoke({\"context\": documents, \"question\": question})\n",
    "        return {\n",
    "            \"documents\": documents, \n",
    "            \"question\": question, \n",
    "            \"generation\": generation, \n",
    "            \"number_of_document_tries\": attempts, \n",
    "            \"upload_status\": upload_status,\n",
    "            \"source_type\": source_type\n",
    "        }\n",
    "    \n",
    "\n",
    "def grade_documents(state: GraphState):\n",
    "        \"\"\"\n",
    "        Determines whether the retrieved documents are relevant to the question.\n",
    "\n",
    "        Args:\n",
    "            state (dict): The current graph state\n",
    "\n",
    "        Returns:\n",
    "            state (dict): Updates documents key with only filtered relevant documents\n",
    "        \"\"\"\n",
    "\n",
    "        print(\"---CHECK DOCUMENT RELEVANCE TO QUESTION---\")\n",
    "        question = state[\"question\"]\n",
    "        documents = state[\"documents\"]\n",
    "        attempts = state.get(\"number_of_document_tries\", 0)\n",
    "        upload_status = state.get(\"upload_status\", \"False\")\n",
    "        source_type = state.get(\"source_type\", \"unknown\")\n",
    "\n",
    "        # Score each doc\n",
    "        filtered_docs = []\n",
    "        for d in documents:\n",
    "            score = retrieval_grader.invoke(\n",
    "                {\"question\": question, \"document\": d.page_content}\n",
    "            )\n",
    "            # Handle both dict and Pydantic model responses\n",
    "            grade = score.binary_score if hasattr(score, 'binary_score') else score.get('binary_score', 'no')\n",
    "            if grade == \"yes\":\n",
    "                print(\"---GRADE: DOCUMENT RELEVANT---\")\n",
    "                filtered_docs.append(d)\n",
    "            else:\n",
    "                print(\"---GRADE: DOCUMENT NOT RELEVANT---\")\n",
    "                continue\n",
    "        return {\n",
    "            \"documents\": filtered_docs, \n",
    "            \"question\": question, \n",
    "            \"number_of_document_tries\": attempts, \n",
    "            \"upload_status\": upload_status,\n",
    "            \"source_type\": source_type\n",
    "        }\n",
    "    \n",
    "\n",
    "\n",
    "def transform_query(state: GraphState):\n",
    "        \"\"\"\n",
    "        Transform the query to produce a better question.\n",
    "\n",
    "        Args:\n",
    "            state (dict): The current graph state\n",
    "\n",
    "        Returns:\n",
    "            state (dict): Updates question key with a re-phrased question\n",
    "        \"\"\"\n",
    "\n",
    "        print(\"---TRANSFORM QUERY---\")\n",
    "        question = state[\"question\"]\n",
    "        documents = state[\"documents\"]\n",
    "        current_attempts = state.get(\"number_of_document_tries\", 0)\n",
    "        upload_status = state.get(\"upload_status\", \"False\")\n",
    "        source_type = state.get(\"source_type\", \"unknown\")\n",
    "\n",
    "        # Re-write question\n",
    "        better_question = question_rewriter.invoke({\"question\": question})\n",
    "        \n",
    "        # Increment the number of attempts\n",
    "        new_attempts = current_attempts + 1\n",
    "        print(f\"---INCREMENTING ATTEMPTS: {new_attempts}---\")\n",
    "        \n",
    "        return {\n",
    "            \"documents\": documents, \n",
    "            \"question\": better_question, \n",
    "            \"number_of_document_tries\": new_attempts, \n",
    "            \"upload_status\": upload_status,\n",
    "            \"source_type\": source_type\n",
    "        }\n",
    "    \n",
    "\n",
    "\n",
    "def web_search(state: GraphState):\n",
    "        \"\"\"\n",
    "        Web search based on the re-phrased question.\n",
    "\n",
    "        Args:\n",
    "            state (dict): The current graph state\n",
    "\n",
    "        Returns:\n",
    "            state (dict): Updates documents key with appended web results\n",
    "        \"\"\"\n",
    "\n",
    "        print(\"---WEB SEARCH---\")\n",
    "        question = state[\"question\"]\n",
    "        attempts = state.get(\"number_of_document_tries\", 0)\n",
    "        upload_status = state.get(\"upload_status\", \"False\")\n",
    "\n",
    "        # Web search\n",
    "        docs = web_search_tool.invoke({\"query\": question})\n",
    "        web_results = \"\\n\".join([d[\"content\"] for d in docs])\n",
    "        web_results = Document(page_content=web_results)\n",
    "\n",
    "        return {\n",
    "            \"documents\": web_results, \n",
    "            \"question\": question, \n",
    "            \"number_of_document_tries\": attempts, \n",
    "            \"upload_status\": upload_status,\n",
    "            \"source_type\": \"websearch\"\n",
    "        }\n",
    "    \n",
    "\n",
    "\n",
    "    ### edges \n",
    "\n",
    "def route_question(state: GraphState):\n",
    "        \"\"\"\n",
    "        Route question to web search or RAG.\n",
    "\n",
    "        Args:\n",
    "            state (dict): The current graph state\n",
    "\n",
    "        Returns:\n",
    "            str: Next node to call\n",
    "        \"\"\"\n",
    "\n",
    "        print(\"---ROUTE QUESTION---\")\n",
    "        question = state[\"question\"]\n",
    "        source = question_router.invoke({\"question\": question})\n",
    "        # Handle both dict and Pydantic model responses\n",
    "        datasource = source.datasource if hasattr(source, 'datasource') else source.get('datasource', 'vectorstore')\n",
    "        \n",
    "        if datasource == \"web_search\":\n",
    "            print(\"---ROUTE QUESTION TO WEB SEARCH---\")\n",
    "            return \"web_search\"\n",
    "        elif datasource == \"vectorstore\":\n",
    "            print(\"---ROUTE QUESTION TO RAG---\")\n",
    "            return \"vectorstore\"\n",
    "        \n",
    "        \n",
    "def grade_generation_v_documents_and_question(state:GraphState ):\n",
    "        \"\"\"\n",
    "        Determines whether the generation is grounded in the document and answers question.\n",
    "        Only routes to human-in-the-loop for web search results.\n",
    "\n",
    "        Args:\n",
    "            state (dict): The current graph state\n",
    "\n",
    "        Returns:\n",
    "            str: Decision for next node to call\n",
    "        \"\"\"\n",
    "\n",
    "        print(\"---CHECK HALLUCINATIONS---\")\n",
    "        question = state[\"question\"]\n",
    "        documents = state[\"documents\"]  \n",
    "        generation = state[\"generation\"]\n",
    "        source_type = state.get(\"source_type\", \"unknown\")\n",
    "\n",
    "        score = hallucination_grader.invoke(\n",
    "            {\"documents\": documents, \"generation\": generation}\n",
    "        )\n",
    "        # Handle both dict and Pydantic model responses\n",
    "        grade = score.binary_score if hasattr(score, 'binary_score') else score.get('binary_score', 'no')\n",
    "\n",
    "        # Check hallucination\n",
    "        if grade == \"yes\":\n",
    "            print(\"---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\")\n",
    "            # Check question-answering\n",
    "            print(\"---GRADE GENERATION vs QUESTION---\")\n",
    "            score = answer_grader.invoke({\"question\": question, \"generation\": generation})\n",
    "            # Handle both dict and Pydantic model responses\n",
    "            grade = score.binary_score if hasattr(score, 'binary_score') else score.get('binary_score', 'no')\n",
    "            if grade == \"yes\":\n",
    "                print(\"---DECISION: GENERATION ADDRESSES QUESTION---\")\n",
    "                # Only allow human-in-the-loop for web search results\n",
    "                if source_type == \"websearch\":\n",
    "                    print(\"---WEB SEARCH RESULT: ROUTE TO HUMAN DECISION---\")\n",
    "                    return \"useful_websearch\"\n",
    "                else:\n",
    "                    print(\"---VECTOR STORE RESULT: END PROCESS---\")\n",
    "                    return \"useful_vectorstore\"\n",
    "            else:\n",
    "                print(\"---DECISION: GENERATION DOES NOT ADDRESS QUESTION---\")\n",
    "                return \"not useful\"\n",
    "        else:\n",
    "            print(\"---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---\")\n",
    "            return \"not supported\"\n",
    "        \n",
    "\n",
    "def route_question_after_attempts(state: GraphState):\n",
    "        \"\"\"\n",
    "        Route based on document relevance and attempt count.\n",
    "        \n",
    "        Args:\n",
    "            state (dict): The current graph state\n",
    "\n",
    "        Returns:\n",
    "            str: Next node to call\n",
    "        \"\"\"\n",
    "\n",
    "        print(\"---ASSESS GRADED DOCUMENTS---\")\n",
    "        filtered_documents = state[\"documents\"]\n",
    "        attempts = state.get(\"number_of_document_tries\", 0)\n",
    "\n",
    "        if not filtered_documents:\n",
    "            # No relevant documents found\n",
    "            print(\"---NO RELEVANT DOCUMENTS FOUND---\")\n",
    "            print(f\"---ATTEMPT NUMBER: {attempts}---\")\n",
    "            \n",
    "            if attempts >= 3:\n",
    "                print(\"---ROUTE TO WEB SEARCH AFTER 3 ATTEMPTS---\")\n",
    "                return \"web_search\"\n",
    "            else:\n",
    "                print(\"---ROUTE TO TRANSFORM QUERY (CONTINUE TRYING)---\")\n",
    "                return \"transform_query\"\n",
    "        else:\n",
    "            # We have relevant documents, so generate answer\n",
    "            print(\"---DECISION: GENERATE---\")\n",
    "            return \"generate\"\n",
    "        \n",
    "\n",
    "def human_in_the_loop(state: GraphState):\n",
    "        \"\"\"\n",
    "        Human-in-the-loop intervention for deciding whether to upload web search results.\n",
    "        \n",
    "        This node will be interrupted by the graph, allowing human decision making.\n",
    "        The human can set upload_status in the state to control the next action.\n",
    "\n",
    "        Args:\n",
    "            state (dict): The current graph state\n",
    "            \n",
    "        Returns:\n",
    "            state (dict): State with human decision for upload\n",
    "        \"\"\"\n",
    "        print(\"---HUMAN IN THE LOOP INTERVENTION REQUIRED---\")\n",
    "        print(\"---WAITING FOR HUMAN DECISION ON UPLOADING WEB SEARCH RESULT---\")\n",
    "        \n",
    "        question = state[\"question\"]\n",
    "        generation = state[\"generation\"]\n",
    "        documents = state[\"documents\"]\n",
    "        attempts = state.get(\"number_of_document_tries\", 0)\n",
    "        source_type = state.get(\"source_type\", \"unknown\")\n",
    "        \n",
    "        # The upload_status will be set by human intervention\n",
    "        # Default to \"False\" if not set by human\n",
    "        upload_status = state.get(\"upload_status\", \"False\")\n",
    "        \n",
    "        print(f\"Question: {question}\")\n",
    "        print(f\"Generated Answer: {generation}\")\n",
    "        print(f\"Source Type: {source_type}\")\n",
    "        print(f\"Upload Status: {upload_status}\")\n",
    "        \n",
    "        return {\n",
    "            \"question\": question,\n",
    "            \"generation\": generation,\n",
    "            \"documents\": documents,\n",
    "            \"number_of_document_tries\": attempts,\n",
    "            \"upload_status\": upload_status,\n",
    "            \"source_type\": source_type\n",
    "        }\n",
    "        \n",
    "\n",
    "def decide_to_upload(state: GraphState):\n",
    "        \"\"\"\n",
    "        Decide whether to upload the generated answer to vector store based on human decision.\n",
    "        \n",
    "        Args:\n",
    "            state (dict): The current graph state\n",
    "            \n",
    "        Returns:\n",
    "            str: \"yes\" to upload, \"no\" to skip\n",
    "        \"\"\"\n",
    "        print(\"---DECIDE TO UPLOAD---\")\n",
    "        upload_status = state.get(\"upload_status\", \"False\")\n",
    "        \n",
    "        if upload_status.lower() in [\"true\", \"yes\", \"1\"]:\n",
    "            print(\"---DECISION: UPLOAD TO VECTOR STORE---\")\n",
    "            return \"yes\"\n",
    "        else:\n",
    "            print(\"---DECISION: DO NOT UPLOAD---\")\n",
    "            return \"no\"\n",
    "        \n",
    "\n",
    "def send_answer_vectorstore(state: GraphState):\n",
    "        \"\"\"\n",
    "        Send answer from websearch to vectorstore\n",
    "\n",
    "        Args:\n",
    "            state (dict): The current graph state\n",
    "            \n",
    "        Returns:\n",
    "            state (dict): Updated state after upload\n",
    "        \"\"\"\n",
    "\n",
    "        print(\"---SENDING ANSWER FROM WEBSEARCH TO VECTORSTORE---\")\n",
    "        question = state[\"question\"]\n",
    "        answer = state[\"generation\"]\n",
    "        documents = state[\"documents\"]\n",
    "        attempts = state.get(\"number_of_document_tries\", 0)\n",
    "        source_type = state.get(\"source_type\", \"unknown\")\n",
    "\n",
    "        print(\"---PREPARING TO UPLOAD GENERATED ANSWER AND SOURCE DOCUMENTS TO ASTRA DB---\")\n",
    "        print(f\"---SOURCE TYPE: {source_type}---\")\n",
    "\n",
    "        try:\n",
    "            uploader = upload_generated_answers(documents, answer)\n",
    "            upload_result = uploader.upload_answer()\n",
    "            print(\"---UPLOAD SUCCESSFUL---\")\n",
    "            \n",
    "            return {\n",
    "                \"question\": question,\n",
    "                \"generation\": answer,\n",
    "                \"documents\": documents,\n",
    "                \"number_of_document_tries\": attempts,\n",
    "                \"upload_status\": \"completed\",\n",
    "                \"source_type\": source_type\n",
    "            }\n",
    "        except Exception as e:\n",
    "            print(f\"---UPLOAD FAILED: {e}---\")\n",
    "            return {\n",
    "                \"question\": question,\n",
    "                \"generation\": answer,\n",
    "                \"documents\": documents,\n",
    "                \"number_of_document_tries\": attempts,\n",
    "                \"upload_status\": \"failed\",\n",
    "                \"source_type\": source_type\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d4583cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new graph instance\n",
    "graph = StateGraph(GraphState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7072e782",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x792f79634140>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.add_node(\"web_search\", web_search) \n",
    "graph.add_node(\"retrieve\", retrieve)\n",
    "graph.add_node(\"grade_documents\", grade_documents)\n",
    "graph.add_node(\"generate\", generate)\n",
    "graph.add_node(\"transform_query\", transform_query)\n",
    "graph.add_node(\"human_in_the_loop\", human_in_the_loop)\n",
    "graph.add_node(\"send_answer_vectorstore\", send_answer_vectorstore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7fa16461",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.add_conditional_edges(\n",
    "            START, \n",
    "            route_question, \n",
    "            {\n",
    "                \"web_search\": \"web_search\",\n",
    "                \"vectorstore\": \"retrieve\"\n",
    "            },\n",
    "        )\n",
    "        \n",
    "graph.add_edge(\"web_search\", \"generate\")\n",
    "graph.add_edge(\"retrieve\", \"grade_documents\")\n",
    "\n",
    "graph.add_conditional_edges(\n",
    "    \"grade_documents\",\n",
    "    route_question_after_attempts,\n",
    "    {\n",
    "                \"generate\": \"generate\",\n",
    "                \"web_search\": \"web_search\",\n",
    "                \"transform_query\": \"transform_query\"\n",
    "            },\n",
    "        )\n",
    "        \n",
    "graph.add_edge(\"transform_query\", \"retrieve\")\n",
    "\n",
    "graph.add_conditional_edges(\n",
    "            \"generate\",\n",
    "            grade_generation_v_documents_and_question,\n",
    "            {\n",
    "                \"not supported\": END,  # End if hallucinated - avoid infinite loops\n",
    "                \"useful_websearch\": \"human_in_the_loop\",  # Go to human decision for web search uploads\n",
    "                \"useful_vectorstore\": END,  # End directly for vector store results\n",
    "                \"not useful\": \"transform_query\"  # Only retry if answer doesn't address question\n",
    "            },\n",
    "        )   \n",
    "\n",
    "        # Human decides whether to upload the web search result to vector store\n",
    "graph.add_conditional_edges(\n",
    "            \"human_in_the_loop\",\n",
    "            decide_to_upload,\n",
    "            {\n",
    "                \"yes\": \"send_answer_vectorstore\",\n",
    "                \"no\": END\n",
    "            },\n",
    "        )\n",
    "        \n",
    "graph.add_edge(\"send_answer_vectorstore\", END)\n",
    "\n",
    "# Compile the graph\n",
    "memory_saver = MemorySaver()\n",
    "compiled_graph = graph.compile(\n",
    "            interrupt_before=[\"human_in_the_loop\"],\n",
    "            checkpointer=memory_saver\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "79adba03",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to reach https://mermaid.ink/ API while trying to render your graph. Status code: 204.\n\nTo resolve this issue:\n1. Check your internet connection and try again\n2. Try with higher retry settings: `draw_mermaid_png(..., max_retries=5, retry_delay=2.0)`\n3. Use the Pyppeteer rendering method which will render your graph locally in a browser: `draw_mermaid_png(..., draw_method=MermaidDrawMethod.PYPPETEER)`",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mIPython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdisplay\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Image, display\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m y = display(Image(\u001b[43mcompiled_graph\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxray\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdraw_mermaid_png\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(y)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/Aegis/.venv/lib/python3.12/site-packages/langchain_core/runnables/graph.py:702\u001b[39m, in \u001b[36mGraph.draw_mermaid_png\u001b[39m\u001b[34m(self, curve_style, node_colors, wrap_label_n_words, output_file_path, draw_method, background_color, padding, max_retries, retry_delay, frontmatter_config)\u001b[39m\n\u001b[32m    692\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrunnables\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgraph_mermaid\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa: PLC0415\u001b[39;00m\n\u001b[32m    693\u001b[39m     draw_mermaid_png,\n\u001b[32m    694\u001b[39m )\n\u001b[32m    696\u001b[39m mermaid_syntax = \u001b[38;5;28mself\u001b[39m.draw_mermaid(\n\u001b[32m    697\u001b[39m     curve_style=curve_style,\n\u001b[32m    698\u001b[39m     node_colors=node_colors,\n\u001b[32m    699\u001b[39m     wrap_label_n_words=wrap_label_n_words,\n\u001b[32m    700\u001b[39m     frontmatter_config=frontmatter_config,\n\u001b[32m    701\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m702\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw_mermaid_png\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    703\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmermaid_syntax\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmermaid_syntax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    704\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_file_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_file_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdraw_method\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdraw_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    706\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbackground_color\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbackground_color\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    707\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    708\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    709\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretry_delay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_delay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    710\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/Aegis/.venv/lib/python3.12/site-packages/langchain_core/runnables/graph_mermaid.py:310\u001b[39m, in \u001b[36mdraw_mermaid_png\u001b[39m\u001b[34m(mermaid_syntax, output_file_path, draw_method, background_color, padding, max_retries, retry_delay)\u001b[39m\n\u001b[32m    304\u001b[39m     img_bytes = asyncio.run(\n\u001b[32m    305\u001b[39m         _render_mermaid_using_pyppeteer(\n\u001b[32m    306\u001b[39m             mermaid_syntax, output_file_path, background_color, padding\n\u001b[32m    307\u001b[39m         )\n\u001b[32m    308\u001b[39m     )\n\u001b[32m    309\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m draw_method == MermaidDrawMethod.API:\n\u001b[32m--> \u001b[39m\u001b[32m310\u001b[39m     img_bytes = \u001b[43m_render_mermaid_using_api\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    311\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmermaid_syntax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    312\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_file_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_file_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    313\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbackground_color\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbackground_color\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    314\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    315\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_delay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_delay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    316\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    317\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    318\u001b[39m     supported_methods = \u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m.join([m.value \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m MermaidDrawMethod])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/Aegis/.venv/lib/python3.12/site-packages/langchain_core/runnables/graph_mermaid.py:463\u001b[39m, in \u001b[36m_render_mermaid_using_api\u001b[39m\u001b[34m(mermaid_syntax, output_file_path, background_color, file_type, max_retries, retry_delay)\u001b[39m\n\u001b[32m    458\u001b[39m     \u001b[38;5;66;03m# For other status codes, fail immediately\u001b[39;00m\n\u001b[32m    459\u001b[39m     msg = (\n\u001b[32m    460\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFailed to reach https://mermaid.ink/ API while trying to render \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    461\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33myour graph. Status code: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse.status_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    462\u001b[39m     ) + error_msg_suffix\n\u001b[32m--> \u001b[39m\u001b[32m463\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[32m    465\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (requests.RequestException, requests.Timeout) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    466\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attempt < max_retries:\n\u001b[32m    467\u001b[39m         \u001b[38;5;66;03m# Exponential backoff with jitter\u001b[39;00m\n",
      "\u001b[31mValueError\u001b[39m: Failed to reach https://mermaid.ink/ API while trying to render your graph. Status code: 204.\n\nTo resolve this issue:\n1. Check your internet connection and try again\n2. Try with higher retry settings: `draw_mermaid_png(..., max_retries=5, retry_delay=2.0)`\n3. Use the Pyppeteer rendering method which will render your graph locally in a browser: `draw_mermaid_png(..., draw_method=MermaidDrawMethod.PYPPETEER)`"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fa454c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph compiled successfully!\n",
      "Graph nodes: ['__start__', 'web_search', 'retrieve', 'grade_documents', 'generate', 'transform_query', 'human_in_the_loop', 'send_answer_vectorstore', '__end__']\n",
      "Graph has 9 nodes\n",
      "\n",
      "Ready to process questions!\n",
      "Example usage:\n",
      "result = compiled_graph.invoke({\"question\": \"Hello, how are you?\"}, config=test_config)\n"
     ]
    }
   ],
   "source": [
    "# Test the compiled graph\n",
    "print(\"Graph compiled successfully!\")\n",
    "print(f\"Graph nodes: {list(compiled_graph.get_graph().nodes)}\")\n",
    "print(f\"Graph has {len(compiled_graph.get_graph().nodes)} nodes\")\n",
    "\n",
    "# Test with a simple question (this will require human intervention if it goes to web search)\n",
    "test_config = {\"configurable\": {\"thread_id\": \"test_thread\"}}\n",
    "print(\"\\nReady to process questions!\")\n",
    "print(\"Example usage:\")\n",
    "print('result = compiled_graph.invoke({\"question\": \"Hello, how are you?\"}, config=test_config)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "33ce0389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CHECK HALLUCINATIONS---\n",
      "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
      "---GRADE GENERATION vs QUESTION---\n",
      "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
      "---GRADE GENERATION vs QUESTION---\n",
      "---DECISION: GENERATION ADDRESSES QUESTION---\n",
      "---WEB SEARCH RESULT: ROUTE TO HUMAN DECISION---\n",
      "---DECISION: GENERATION ADDRESSES QUESTION---\n",
      "---WEB SEARCH RESULT: ROUTE TO HUMAN DECISION---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CHECK HALLUCINATIONS---\n",
      "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
      "---GRADE GENERATION vs QUESTION---\n",
      "---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\n",
      "---GRADE GENERATION vs QUESTION---\n",
      "---DECISION: GENERATION ADDRESSES QUESTION---\n",
      "---WEB SEARCH RESULT: ROUTE TO HUMAN DECISION---\n",
      "---DECISION: GENERATION ADDRESSES QUESTION---\n",
      "---WEB SEARCH RESULT: ROUTE TO HUMAN DECISION---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'configurable': {'thread_id': '1',\n",
       "  'checkpoint_ns': '',\n",
       "  'checkpoint_id': '1f09e02b-ccdc-6734-8010-d07d845f2dc4'}}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Update the state and continue execution\n",
    "compiled_graph.update_state(config, {\n",
    "    \"upload_status\": \"False\"  \n",
    "})\n",
    "\n",
    "# Continue the graph execution after updating state\n",
    "result = compiled_graph.invoke(None, config)sult = compiled_graph.invoke({\"question\":\"What is prompt engineering?\" , \"number_of_document_tries\":0 }, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "01583a4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---HUMAN IN THE LOOP INTERVENTION REQUIRED---\n",
      "---WAITING FOR HUMAN DECISION ON UPLOADING WEB SEARCH RESULT---\n",
      "Question: what is jordan\n",
      "Generated Answer: Jordan can refer to two very different things:\n",
      "\n",
      "1. **The country**: Jordan is a country in the Middle East, slightly smaller than Portugal. It borders Syria to the north, Iraq to the east, Saudi Arabia to the south, and Israel and the West Bank to the west. It became an independent kingdom in 1946 after being part of the Ottoman Empire and later a British mandate. Jordan is known for its ancient history, including the biblical kingdoms of Moab, Gilead, and Edom, and the famous archaeological site of Petra.\n",
      "\n",
      "2. **Jordan Peterson**: A Canadian psychologist, author, and media commentator (born 1962). He gained widespread attention for his views on cultural and political issues and is known for his books like \"12 Rules for Life\" and \"Beyond Order\".\n",
      "Source Type: websearch\n",
      "Upload Status: yes\n",
      "---DECIDE TO UPLOAD---\n",
      "---DECISION: UPLOAD TO VECTOR STORE---\n",
      "---SENDING ANSWER FROM WEBSEARCH TO VECTORSTORE---\n",
      "---PREPARING TO UPLOAD GENERATED ANSWER AND SOURCE DOCUMENTS TO ASTRA DB---\n",
      "---SOURCE TYPE: websearch---\n",
      "Connected to Astra DB: ['astra_vector_langchain']\n",
      "Connected to Astra DB successfully!\n",
      "Connected to Astra DB: ['astra_vector_langchain']\n",
      "Connected to Astra DB successfully!\n",
      "Uploading answer and source documents to Astra DB...\n",
      "Uploading answer and source documents to Astra DB...\n",
      "---UPLOAD SUCCESSFUL---\n",
      "---UPLOAD SUCCESSFUL---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---HUMAN IN THE LOOP INTERVENTION REQUIRED---\n",
      "---WAITING FOR HUMAN DECISION ON UPLOADING WEB SEARCH RESULT---\n",
      "Question: what is jordan\n",
      "Generated Answer: Jordan can refer to two very different things:\n",
      "\n",
      "1. **The country**: Jordan is a country in the Middle East, slightly smaller than Portugal. It borders Syria to the north, Iraq to the east, Saudi Arabia to the south, and Israel and the West Bank to the west. It became an independent kingdom in 1946 after being part of the Ottoman Empire and later a British mandate. Jordan is known for its ancient history, including the biblical kingdoms of Moab, Gilead, and Edom, and the famous archaeological site of Petra.\n",
      "\n",
      "2. **Jordan Peterson**: A Canadian psychologist, author, and media commentator (born 1962). He gained widespread attention for his views on cultural and political issues and is known for his books like \"12 Rules for Life\" and \"Beyond Order\".\n",
      "Source Type: websearch\n",
      "Upload Status: yes\n",
      "---DECIDE TO UPLOAD---\n",
      "---DECISION: UPLOAD TO VECTOR STORE---\n",
      "---SENDING ANSWER FROM WEBSEARCH TO VECTORSTORE---\n",
      "---PREPARING TO UPLOAD GENERATED ANSWER AND SOURCE DOCUMENTS TO ASTRA DB---\n",
      "---SOURCE TYPE: websearch---\n",
      "Connected to Astra DB: ['astra_vector_langchain']\n",
      "Connected to Astra DB successfully!\n",
      "Connected to Astra DB: ['astra_vector_langchain']\n",
      "Connected to Astra DB successfully!\n",
      "Uploading answer and source documents to Astra DB...\n",
      "Uploading answer and source documents to Astra DB...\n",
      "---UPLOAD SUCCESSFUL---\n",
      "---UPLOAD SUCCESSFUL---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'what is jordan',\n",
       " 'generation': 'Jordan can refer to two very different things:\\n\\n1. **The country**: Jordan is a country in the Middle East, slightly smaller than Portugal. It borders Syria to the north, Iraq to the east, Saudi Arabia to the south, and Israel and the West Bank to the west. It became an independent kingdom in 1946 after being part of the Ottoman Empire and later a British mandate. Jordan is known for its ancient history, including the biblical kingdoms of Moab, Gilead, and Edom, and the famous archaeological site of Petra.\\n\\n2. **Jordan Peterson**: A Canadian psychologist, author, and media commentator (born 1962). He gained widespread attention for his views on cultural and political issues and is known for his books like \"12 Rules for Life\" and \"Beyond Order\".',\n",
       " 'number_of_document_tries': 0,\n",
       " 'documents': Document(metadata={}, page_content='Jordan is a young state that occupies an ancient land, one that bears the traces of many civilizations. Separated from ancient Palestine by the Jordan River, the region played a prominent role in biblical history. The ancient biblical kingdoms of Moab, Gilead, and Edom lie within its borders as does the famed red stone city of Petra, the capital of the Nabataean kingdom and of the Roman province of Arabia Petraea. British traveler Gertrude Bell said of Petra, It is like a fairy tale city, all [...] pink and wonderful. Part of the Ottoman Empire until 1918 and later a mandate of the United Kingdom, Jordan has been an independent kingdom since 1946. It is among the most politically liberal countries of the Arab world, and, although it shares in the troubles affecting the region, its rulers have expressed a commitment to maintaining peace and stability. [...] Slightly smaller in area than the country of Portugal, Jordan is bounded to the north by Syria, to the east by Iraq, to the southeast and south by Saudi Arabia, and to the west by Israel and the West Bank. The West Bank area (so named because it lies just west of the Jordan River) was under Jordanian rule from 1948 to 1967 and was then occupied by Israel during the Six-Day War. In 1988, as Palestinian leaders asserted their claim over the West Bank during the first intifada, Jordan renounced\\nJordan Bernt Peterson (born 12 June 1962) is a Canadian psychologist, author, and media commentator. He received widespread attention in the late 2010s for his views on cultural and political issues. Often characterized as conservative, Peterson has described himself as a classical liberal and a traditionalist. [...] referred to as \"the most influential Biblical interpreter in the world today\".( [...] During a press tour to promote her 2022 film _Don\\'t Worry Darling_, Olivia Wilde said the sinister character Frank was inspired by Peterson. She described him as \"this insane man, Jordan Peterson, who is this pseudo-intellectual hero to the incel community.\"( Peterson called the film \"the latest bit of propaganda disseminated by the woke, self-righteous bores and bullies who now dominate Hollywood.\"( He also criticized the term \"incel\", calling it a \"casual insult\" for men who are \"lonesome and\\n## Watch The Latest Video\\n\\n## About\\n\\nDr. Jordan B. Peterson is a renowned psychologist, author, and online educator. His bestselling books, including 12 Rules for Life and Beyond Order, have sold millions of copies worldwide. Dr. Petersons lectures and podcasts consistently attract large audiences, providing valuable insights into topics such as mythology, psychology, and personal development. [...] ## BISHOP ROBERT BARRON\\n\\nfounder of Word on Fire\\n\\n## Jordan Peterson has wrestled into existence another iconic masterpiece.\\n\\nJordan Peterson has wrestled into existence another iconic masterpiece, highlighting that our ancient stories filter what we see and create our perception of reality. Read on to understand the provocative arguments of our age at an entirely new level.\\n\\n## MEHMET OZ, MD\\n\\nprofessor emeritus, Columbia University [...] He has taught at prestigious universities, published numerous scientific papers, and developed online programs that help individuals explore their personalities and improve their lives. With a diverse background and adventurous spirit, Dr. Peterson has engaged in various activities and occupations, bringing a wealth of experiences to his work. His influential presence extends across social media platforms, and he continues to make significant contributions to the field of psychology and\\nIn 1927, the British administration of the Palestinian Mandate established the Palestine Currency Board which issued the Palestine pound which was the official currency in both Mandatory Palestine and the Emirate of Transjordan. Though Jordan became an independent kingdom on 25 May 1946, it continued to use the Palestinian pound for a while. In 1949, it passed the Provisional Act No. 35 of 1949, which established the Jordan Currency Board as the sole authority in the kingdom entitled to issue [...] In 1949, banknotes were issued by the Jordan Currency Board in denominations of 12, 1, 5, 10 and 50 dinars. They bore the country\\'s official name, \"The Hashemite Kingdom of the Jordan\". 20 dinar notes were introduced in 1977. The 50 dinar note was redesigned and the 12 dinar notes were replaced by coins in 1999.\\n\\n### Issues by the Jordan Currency Board\\n\\n[edit]\\n\\n#### First issue\\n\\n[edit] [...] The Jordanian dinar (Arabic:  \\u200e; code: JOD; unofficially abbreviated as JD) has been the currency of Jordan since 1950. The dinar is divided into 100 qirsh (also called piastres) or 1000 fulus \"Fils (currency)\"). Fils are effectively obsolete; however, monetary amounts are still written to three decimal places representing fils. It is pegged to the US dollar.\\nImage 4: The image features Dr. Jordan B. Peterson, a well-known psychologist and public speaker, standing against a dramatic red background with a target-like design behind him, symbolizing depth and focus. He is dressed in a dark suit, white shirt, and red tie, exuding a professional and authoritative presence. The text \"PETERSON ACADEMY PRESENTS\" is at the top, and \"MAPS OF MEANING\" in large, bold letters dominates the center, with \"Dr. Jordan B. Peterson\" below, indicating his authorship.'),\n",
       " 'upload_status': 'completed',\n",
       " 'source_type': 'websearch'}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resumed_result = compiled_graph.invoke(None, config)\n",
    "resumed_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "77d1c6c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('human_in_the_loop',)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_nodes = state.next\n",
    "next_nodes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Aegis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
